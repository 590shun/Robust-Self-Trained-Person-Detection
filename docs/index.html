

<!DOCTYPE html>
<html>
<head>
	<title>Robust Self-Trained Person Detection for Vulnerable Road Users </title>
    <link rel="stylesheet" type="text/css" href="./pvg.css">
    <link rel="shortcut icon" type="image/png" href="./img/cvpaper_challenge.png">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
</head>

<body>
<script type="text/javascript" src="./header.js"></script>

<style>
a.myclass {
    color:#DE382D;
    text-decoration: underline
}
</style>

<style>
a.link {
    text-decoration: underline
}
</style>


<h1 align="center" style="font-size: 30pt;"><b>Robust Self-Trained Person Detection for Vulnerable Road Users </b></h1><br/>

<center>
    <font color="#c7254e">Conference on Computer Vision and Pattern Recognition (CVPR) 2021 Workshop on Beyond Fairness: Towards a Just, Equitable, and Accountable Computer Vision<br><b></b><br></font><br><br>
    <a href="http://twitter.com/k0gu_chan" class="">Shunsuke Kogure</a><sup>1,3</sup> &emsp; Kai Watabe</a><sup>2,3</sup> &emsp;  <a href="https://twitter.com/FragileGoodwill" clss="">Ryosuke Yamada<sup>2,3</sup> &emsp; Yoshimitsu Aoki<sup>1</sup><br>&emsp; <a href="http://www.is.fr.dendai.ac.jp/" class="">Akio Nakamura</a><sup>2</sup> &emsp; <a href="http://hirokatsukataoka.net/" class="">Hirokatsu Kataoka</a><sup>3</sup><br>
    1: Keio University &emsp; 2: Tokyo Denki University &emsp; 3: National Institute of Advanced Industrial Science and Technology (AIST)<br><br>
    <a href="https://drive.google.com/file/d/15kQMi5S6kwKa-_NEblT5To3IOdyZKaBs/view" class="btn btn-secondary btn-lg active" role="button" aria-pressed="true">Paper</a>
    <a href="#dataset" class="btn btn-secondary btn-lg active" role="button" aria-pressed="true">Dataset</a>
    <a href="" class="btn btn-secondary btn-lg active" role="button" aria-pressed="true">Poster</a>
    <a href="https://www.martimbrandao.com/pedestrian-detection-bias/" class="btn btn-secondary btn-lg active" role="button" aria-pressed="true">Related Work</a>
    <br><br>
    <!--<img src="./img/teaser.png" style="width: 100%;"/>-->
</center>

<br>
<h2>Abstract</h2>
<p>
Pedestrian detection is an expected function in automaticdriving and other applications. However, there should be no disparities in miss rates between sensitive attributes, such as age and gender. In this paper, we examine this issue by efficiently expanding and self-training a large-scale person dataset. Specifically, we apply the Weakly-Supervised Person Dataset (WSPD), a pre-trained pedestrian detection network, to the database Places365 to efficiently collect pedestrian data. We also investigate the miss rate disparities between sensitive attributes in the conventional pre-trained model by manually re-annotating bounding boxes for “adult”, “child” and “elderly” attributes in the INRIA Person Dataset. We then collect 3,461,024 images and 9,739,996 bounding boxes from the ‘Self-Trained Pedestrian Dataset (STPD)’. Our pre-trained detector successfully improves the miss rate for adult by up to 9.2%, for children by up to 8.5% and for the elderly by up to 6.5% over the baseline model. However, it should be rememberedthat there is a difference in the effects of improvement in the expansion of the dataset by self-learning depending on the attributes.
</p>

<br>
<h2>Experimental Results</h2>
<br>
coming soon...


<br><br><br>
<h2>Visual Results</h2>
<br>
coming soon...


	
<h2>Citation</h2>
@inproceedings{kogucvpr2021,<br>
&emsp;author     = {Shunsuke Kogure, Kai Watabe, Ryosuke Yamada, Yoshimitsu Aoki, Akio Nakamura, and Hirokatsu Kataoka},<br>
&emsp;title      = {Robust Self-Trained Person Detection for Vulnerable Road Users},<br>
&emsp;journal    = {Computer Vision and Pattern Recognition (CVPR) Workshop on Beyond Fairness: Towards a Just, Equitable, and Accountable Computer Vision},<br>
&emsp;year       = {2021}<br>
}
<br><br>

<a name="dataset"><h2>Dataset Download</h2></a>
<ul>
    <li>
	    coming soon...
    </li>

</ul>
<br><br>

<h2>Acknowledgement</h2></a>
<ul>
    <li> Computational resource of AI Bridging Cloud Infrastructure (ABCI) provided by National Institute of Advanced Industrial Science and Technology (AIST) was used.</li>
</ul>

<br><br><br>
<script type="text/javascript" src="./footer.js"></script>
</body></html>
